{
  "dashboard": {
    "title": "GPU Servers Monitoring",
    "tags": ["gpu", "llm", "inference"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
        "type": "timeseries",
        "title": "GPU Memory Usage",
        "targets": [
          {
            "expr": "gpu_memory_used_bytes / gpu_memory_total_bytes * 100",
            "legendFormat": "GPU {{gpu_id}} Memory %",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100
          }
        }
      },
      {
        "id": 2,
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
        "type": "timeseries",
        "title": "GPU Temperature",
        "targets": [
          {
            "expr": "gpu_temperature_celsius",
            "legendFormat": "GPU {{gpu_id}} Temperature",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "celsius"
          }
        }
      },
      {
        "id": 3,
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
        "type": "timeseries",
        "title": "GPU Utilization",
        "targets": [
          {
            "expr": "gpu_utilization_percent",
            "legendFormat": "GPU {{gpu_id}} Utilization",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100
          }
        }
      },
      {
        "id": 4,
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
        "type": "timeseries",
        "title": "Inference Requests Rate",
        "targets": [
          {
            "expr": "rate(inference_requests_total[5m])",
            "legendFormat": "{{job}} {{endpoint}} {{status}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "reqps"
          }
        }
      },
      {
        "id": 5,
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
        "type": "timeseries",
        "title": "Average Inference Duration",
        "targets": [
          {
            "expr": "rate(inference_duration_seconds_sum[5m]) / rate(inference_duration_seconds_count[5m])",
            "legendFormat": "{{job}} {{endpoint}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "s"
          }
        }
      },
      {
        "id": 6,
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
        "type": "stat",
        "title": "Models Loaded",
        "targets": [
          {
            "expr": "sum(model_loaded)",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "short"
          }
        }
      },
      {
        "id": 7,
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24},
        "type": "timeseries",
        "title": "Tokens Generated",
        "targets": [
          {
            "expr": "rate(inference_tokens_total[5m])",
            "legendFormat": "{{job}} {{type}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "tps"
          }
        }
      },
      {
        "id": 8,
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24},
        "type": "gauge",
        "title": "Active Requests",
        "targets": [
          {
            "expr": "sum(active_requests_gauge)",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "short",
            "min": 0,
            "max": 8
          }
        }
      }
    ],
    "refresh": "10s",
    "time": {
      "from": "now-1h",
      "to": "now"
    }
  }
}
