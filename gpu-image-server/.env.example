# GPU Image Server Configuration
# Copy this to .env and customize

# API port for the load balancer
IMAGE_API_PORT=5100

# Model selection (copy desired model config to models/)
# Options: avatar-sdxl.yaml, avatar-sd15.yaml
DEFAULT_MODEL=avatar-sdxl

# GPU memory settings (RTX 3070 = 8GB)
# Increase if you have more VRAM
CUDA_MEMORY_FRACTION=0.9

# Inference settings
DEFAULT_STEPS=30
DEFAULT_CFG_SCALE=7.0
DEFAULT_IMAGE_SIZE=512x512

# Rate limiting (handled by HeartCode backend, but can add here too)
MAX_CONCURRENT_REQUESTS=4
REQUEST_TIMEOUT=120

# Logging
LOG_LEVEL=info
